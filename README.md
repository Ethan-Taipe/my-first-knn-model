# Optimizaci√≥n y Evaluaci√≥n de un Modelo KNN

Este proyecto consiste en la construcci√≥n, optimizaci√≥n y evaluaci√≥n de un modelo de clasificaci√≥n utilizando el algoritmo **K-Nearest Neighbors (KNN)** sobre un dataset personalizado.

## üìÅ Archivo principal

- `Modelo_knn_optimizado.ipynb`: Notebook donde se desarrolla todo el proceso de an√°lisis, optimizaci√≥n de hiperpar√°metros y evaluaci√≥n final del modelo.

---

## üß† Objetivos del proyecto

- Entrenar un modelo KNN con un valor fijo de `n_neighbors = 11`.
- Explorar combinaciones √≥ptimas de hiperpar√°metros mediante:
  - `GridSearchCV`
  - `RandomizedSearchCV`
- Evaluar el desempe√±o del modelo utilizando validaci√≥n cruzada.
- Visualizar las 5 mejores combinaciones de hiperpar√°metros.
- Reentrenar el modelo con la mejor combinaci√≥n encontrada.
- Evaluar el rendimiento en el conjunto de prueba (accuracy y matriz de confusi√≥n).
- Guardar el modelo final entrenado utilizando `joblib`.

---

## üîß Hiperpar√°metros explorados

Se optimizaron los siguientes hiperpar√°metros del modelo `KNeighborsClassifier`:

- `weights`: ['uniform', 'distance']
- `algorithm`: ['auto', 'ball_tree', 'kd_tree', 'brute']
- `metric`: ['euclidean', 'manhattan', 'chebyshev', 'minkowski']

---

## üß™ Evaluaci√≥n del modelo

- Se utiliz√≥ **validaci√≥n cruzada con 6 folds**.
- La m√©trica de evaluaci√≥n fue la **precisi√≥n (accuracy)**.
- Se compararon m√∫ltiples combinaciones de hiperpar√°metros.
- Se graficaron los 5 mejores resultados tanto para GridSearch como para RandomizedSearch.

---

## ‚úÖ Resultados

- Mejores hiperpar√°metros encontrados:
  ```python
  {'algorithm': 'brute', 'metric': 'manhattan', 'weights': 'distance'}
